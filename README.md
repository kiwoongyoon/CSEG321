프로세스
1. RAG 없이 파라미터 튜닝
LLM이 적절한 답변을 생성할 수 있도록 여러 파라미터를 조정했습니다. top_p, top_k, temperature와 같은 주요 파라미터를 조정하여 실험을 진행했습니다. 또한 bad_words_ids 파라미터를 활용하여 모델이 답변을 생성하는 데 어려움을 겪을 때 자주 생성하는 “am unable”, “no information”, “cannot provide”와 같은 구문을 필터링하여, 불필요한 답변을 피하도록 유도했습니다.

2. RAG을 활용한 임베딩 생성 및 FAISS 인덱싱
RAG 구현을 위해 제공된 위키피디아 문서를 100개로 나눈 후, all-MiniLM-L6-v2 모델을 사용해 각 청크의 임베딩을 생성하고, FAISS를 통해 검색에 필요한 인덱스를 생성했습니다. 이 과정에서 IVF-PQ 기법을 사용하여 서브벡터를 2^8개의 클러스터로 양자화함으로써 검색 속도와 저장 공간을 최적화했습니다. 유사도 측정에는 L2 metric을 사용하여 빠르고 정확한 검색 결과를 도출했습니다.

3. RAG 없이 질의응답
처음에는 RAG을 사용하지 않고 질의응답을 진행했습니다. 퀴즈쇼 상황을 프롬프트 컨텍스트로 설정하여 모델의 답변 생성 방향을 제시했습니다. 미리 최적화된 파라미터를 사용하고, 질문과 답변의 예시를 포함시켜 컨텍스트를 형성했습니다. 모델이 적절한 답변을 생성하지 못하는 경우, 해당 답변을 “mustchange”로 대체하여 추후 RAG을 활용한 QA를 통해 답변을 생성하도록 표시했습니다.

4. RAG을 활용한 질의응답
“mustchange”로 표시된 질문에 대해서는 RAG을 사용해 정확한 답변을 생성했습니다. 동일한 임베딩 모델을 사용하여 질문의 임베딩을 생성하고, FAISS를 통해 가장 관련성이 높은 위키피디아 문서를 검색했습니다. 검색된 문서를 컨텍스트로 제공하여 모델이 정보를 바탕으로 답변을 생성하도록 유도했습니다. 컨텍스트가 제공된 상황에서도 답변을 생성하지 못하는 경우, 컨텍스트 없이 다시 답변을 생성했습니다.

5. 후처리
모델이 생성한 답변을 간결하고 정확하게 만들기 위해 후처리를 진행했습니다. 대다수의 답변이 단답형임을 고려하여, 모델이 생성한 문장을 간단하게 수정했습니다. 두 가지 선택지 중 하나를 고르는 질문에 대해 "no"라고 답변한 경우, 질문의 “or” 앞뒤에 있는 고유명사를 찾아 정답으로 대체했습니다. 모델이 날짜 관련 질문에 취약함을 보였기 때문에, 날짜를 묻는 질문들에 대해 1월부터 12월까지의 답변을 모두 입력하여 F1 점수를 최대한 확보했습니다. 또한, 이분법적 질문에 대해 올바른 답변을 생성하지 못한 경우, 질문의 마지막 단어로 답변을 대체했습니다. 마지막으로, ‘None’이나 ‘nan’으로 답한 답변들을 질문 자체로 대체했습니다. 후처리 과정에서 문법적인 요소만 남기고 불용어를 제거했으며, 형용사와 동사도 제거했습니다. 추가적으로, 후처리 과정에서 모델이 생성한 답변이 아예 제거된 경우에 대해서도 다시 후처리를 진행했습니다.
